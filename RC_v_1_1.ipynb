{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNo8qgssq1JbFatRsZpclqg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asia-kamysh/Random_Coffee/blob/main/RC_v_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgzb45ZMzDCK"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import datetime\n",
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import files, auth\n",
        "from google.auth import default\n",
        "\n",
        "\n",
        "# Authenticate to Google\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Define the name of the current meetings table\n",
        "MEETINGS_CURRENT_TABLE_NAME = 'test_current'\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import pathlib to work with file paths\n",
        "import pathlib\n",
        "print(pathlib.Path().resolve())\n",
        "\n",
        "# Load data from a CSV file into a DataFrame\n",
        "df = pd.read_csv('2024-06-05.csv', sep=',')\n",
        "df.index = df['0']  # Set the index to the first column\n",
        "df = df.drop(columns=['0'])  # Drop the first column\n",
        "\n",
        "# Convert each column in the DataFrame to datetime format\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_datetime(df[col], format='%Y-%m-%d', errors='coerce')\n",
        "\n",
        "# Function to remove time from datetime, keeping only the date\n",
        "def to_date_without_time(dt):\n",
        "    return dt.date()\n",
        "\n",
        "# Apply the function to each element in the DataFrame\n",
        "df = df.applymap(lambda x: to_date_without_time(pd.to_datetime(x)))\n",
        "\n",
        "# Open the Google Sheet and get the first worksheet\n",
        "worksheet = gc.open('Random_Coffee').get_worksheet(0)\n",
        "\n",
        "# Get all values from the worksheet (as a list of rows)\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert the list of rows into a DataFrame\n",
        "data = pd.DataFrame(rows)\n",
        "data.columns = data.iloc[0]  # Set the first row as the column headers\n",
        "data = data.iloc[1:]  # Remove the first row from the DataFrame\n",
        "data = data.set_index('Укажи Имя и Фамилию\\nEnter your first and last name')  # Set the index\n",
        "\n",
        "# Rename the columns\n",
        "data.columns = ['Timestamp', 'Contact', 'Format', 'City', 'Interests', 'Community', 'Language', 'Frequency', 'Intro', 'intro', 'intro', 'STATUS', 'PERSONAL_FORM_LINK']\n",
        "\n",
        "# Replace textual frequency values with numerical values\n",
        "data['Frequency'] = data['Frequency'].replace('Раз в неделю/Once a week', 1)\n",
        "data['Frequency'] = data['Frequency'].replace('Раз в две недели/Once in two weeks', 2)\n",
        "data['Frequency'] = data['Frequency'].replace('Раз в четыре недели/Once in four weeks', 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_matches(data, df):\n",
        "    \"\"\"\n",
        "    Create pairs of people who want to meet, based on certain criteria such as availability,\n",
        "    meeting frequency, format, city, language, and community.\n",
        "\n",
        "    Parameters:\n",
        "    data (DataFrame): Contains metadata about individuals, including their status, meeting frequency, interests, etc.\n",
        "    df (DataFrame): Contains historical meeting data between individuals.\n",
        "\n",
        "    Returns:\n",
        "    pairs (list): List of tuples containing matched pairs.\n",
        "    df (DataFrame): Updated DataFrame with the latest meeting data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Shuffle the DataFrame to ensure random pairings\n",
        "    df = df.sample(frac=1)\n",
        "\n",
        "    # Determine people available to meet in this round\n",
        "    people_to_meet = []\n",
        "    next_round = datetime.date.today()\n",
        "    for name in df.columns:\n",
        "        if name in data.index:\n",
        "            if data.loc[name, 'STATUS'] in ['active', '']:\n",
        "                last_meeting = df[name].max()\n",
        "                # If the time since the last meeting is greater than their meeting frequency, they are available\n",
        "                if next_round - last_meeting > datetime.timedelta(weeks=int(data.loc[name]['Frequency'])):\n",
        "                    people_to_meet.append(name)\n",
        "\n",
        "    # List to store pairs of people who have not met before\n",
        "    pairs = []\n",
        "    already_paired = []\n",
        "\n",
        "    # Iterate over each person to find potential pairs\n",
        "    for i in range(df.shape[0]):\n",
        "        name1 = df.index[i]\n",
        "        if name1 in data.index:\n",
        "            possible_pairs = []\n",
        "            # Look for candidates for each person\n",
        "            for j in range(df.shape[1]):\n",
        "                name2 = df.index[j]\n",
        "                if name2 in data.index and name1 in data.index and name1 in people_to_meet and name2 in people_to_meet:\n",
        "                    # Check if they have not met before\n",
        "                    if df.loc[name1, name2] == datetime.date(2001, 1, 1):\n",
        "                        # Check various criteria for pairing\n",
        "                        format = set(data.loc[name1, 'Format'].split(', ')).intersection(data.loc[name2, 'Format'].split(', '))\n",
        "                        city = (data.loc[name1, 'City'] == data.loc[name2, 'City']) if format == {'Оффлайн/Offline'} else True\n",
        "                        format = bool(format)\n",
        "                        language = bool(set(data.loc[name1, 'Language'].split(', ')).intersection(data.loc[name2, 'Language'].split(', ')))\n",
        "                        community = not (data.loc[name1, 'Community'] == 'Community Global' and data.loc[name2, 'Community'] == 'Community Global')\n",
        "\n",
        "                        # If all criteria are met, add to possible pairs\n",
        "                        if format and city and language and community and (name1 != name2):\n",
        "                            possible_pairs.append(name2)\n",
        "\n",
        "            if possible_pairs and name1 not in already_paired:\n",
        "                interests = data.loc[name1]['Interests'].split(', ')\n",
        "                maxim = 0\n",
        "                possible_pairs = [x for x in possible_pairs if x not in already_paired]\n",
        "                if possible_pairs:\n",
        "                    best_match = possible_pairs[0]\n",
        "                    for name2 in possible_pairs:\n",
        "                        if name2 not in already_paired:\n",
        "                            common_interests = len(set(interests).intersection(set(data.loc[name2]['Interests'].split(', '))))\n",
        "                            if common_interests > maxim:\n",
        "                                best_match = name2\n",
        "                                maxim = common_interests\n",
        "                    # Add the best match to the pairs list\n",
        "                    pairs.append((name1, best_match))\n",
        "                    # Update the DataFrame with the new meeting date\n",
        "                    df.at[name1, best_match] = next_round\n",
        "                    df.at[best_match, name1] = next_round\n",
        "                    already_paired.extend([best_match, name1])\n",
        "\n",
        "    return pairs, df\n",
        "\n",
        "# Initialize variables to track the best matching pairs and the updated DataFrame\n",
        "len_max_pairs = 0\n",
        "max_pairs = []\n",
        "final_updated_df = df\n",
        "\n",
        "# Run the matching process 100 times to find the best possible matches\n",
        "for n in range(100):\n",
        "    pairs, updated_df = create_matches(data, df)\n",
        "    if len(pairs) > len_max_pairs:\n",
        "        max_pairs = pairs\n",
        "        final_updated_df = updated_df\n",
        "\n",
        "pairs = max_pairs\n",
        "updated_df = final_updated_df\n",
        "\n",
        "pairs_to_send = []\n",
        "\n",
        "# Print and prepare the pairs for sending\n",
        "print('the pairs are:')\n",
        "for p in pairs:\n",
        "    n1, n2 = p\n",
        "    print(n1, 'and', n2)\n",
        "    contacts = (data.loc[n1]['Contact'], data.loc[n2]['Contact'])\n",
        "    print(contacts)\n",
        "    com_int = set(data.loc[n1]['Interests'].split(', ')).intersection(set(data.loc[n2]['Interests'].split(', ')))\n",
        "    com_int_rus = [x.split('/')[0] for x in com_int]\n",
        "    com_int_eng = [x.split('/')[1] for x in com_int]\n",
        "    com_lang = list(set(data.loc[n1]['Language'].split(', ')).intersection(set(data.loc[n2]['Language'].split(', '))))[-1]\n",
        "    print('[' + ', '.join(com_int_rus) + ']')\n",
        "    print('[' + ', '.join(com_int_eng) + ']')\n",
        "    print()\n",
        "    pairs_to_send.append([n1, n2, contacts, com_int_rus, com_int_eng])"
      ],
      "metadata": {
        "id": "-7f8Co0XzNax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_pair(pair):\n",
        "    \"\"\"Sends a pair to the bot.\"\"\"\n",
        "\n",
        "    # Extract and clean the first Telegram handle\n",
        "    handle1 = pair[2][0].replace('@', '').replace(' ', '').replace('https://t.me/', '')\n",
        "\n",
        "    # Extract and clean the second Telegram handle\n",
        "    handle2 = pair[2][1].replace('@', '').replace(' ', '').replace('https://t.me/', '')\n",
        "\n",
        "    # Get the common interests\n",
        "    interests = pair[3]\n",
        "\n",
        "    # Define the URL to send the pair data\n",
        "    url = 'http://2.59.41.41:8000/new_pair/'\n",
        "\n",
        "    # Create the data payload\n",
        "    data = {\n",
        "        \"first_match_handle\": handle1,\n",
        "        \"second_match_handle\": handle2,\n",
        "        \"common_interests\": interests\n",
        "    }\n",
        "\n",
        "    # Send the POST request to the server\n",
        "    r = requests.post(url, json=data)\n",
        "\n",
        "    # Raise an error if the request was unsuccessful\n",
        "    r.raise_for_status()\n",
        "\n",
        "# Loop through each pair in the list of pairs to send\n",
        "for pair in pairs_to_send:\n",
        "    # Wait for 3 seconds before sending the next pair\n",
        "    time.sleep(3)\n",
        "\n",
        "    # Send the pair data\n",
        "    send_pair(pair)\n",
        "\n",
        "    # Print confirmation message\n",
        "    print('SENT:')\n",
        "    print(pair)"
      ],
      "metadata": {
        "id": "HvUljQBo1jXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get today's date as a string\n",
        "next_round = str(datetime.date.today())\n",
        "\n",
        "# Save the updated DataFrame to a CSV file\n",
        "updated_df.to_csv(next_round + '.csv', encoding='utf-8-sig')\n",
        "\n",
        "# Download the CSV file\n",
        "files.download(next_round + '.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Cfrx1ZMH2Qxj",
        "outputId": "0e788358-70b1-46b4-9033-e4acd86213ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ff327438-730b-4510-90fa-f79ee5bd00a8\", \"2024-06-16.csv\", 43368)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8RMltSJ5jUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}